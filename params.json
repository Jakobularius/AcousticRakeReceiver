{"name":"Acousticrakereceiver","tagline":"The acoustic rake receiver, a microphone beamformer that uses echoes to improve the noise and interference suppression. Python code to reproduce all the results from the eponymous paper by Ivan Dokmanic, Robin Scheibler, and Martin Vetterli.","body":"Acoustic Rake Receiver\r\n======================\r\n\r\nThis repository contains all the code to reproduce the results of the paper\r\n*Raking the Cocktail Party*.\r\n\r\nWe created a simple framework for simulation of room acoustics in object\r\noriented python and apply it to perform numerical experiments related to\r\nthis paper. All the figures and sound samples can be recreated by calling\r\nsimple scripts leveraging this framework. We strongly hope that this code\r\nwill be useful beyond the scope of this paper and plan to develop it into\r\na standalone python package in the future.\r\n\r\nWe are available for any question or request relating to either the code\r\nor the theory behind it. Just ask!\r\n\r\nAbstract\r\n--------\r\n\r\nWe present the concept of an acoustic rake receiver (ARR) — a microphone\r\nbeamformer that uses echoes to improve the noise and interference suppression.\r\nThe rake idea is well-known in wireless communications. It involves\r\nconstructively combining different multipath components that arrive at the\r\nreceiver antennas. Unlike typical spread-spectrum signals used in wireless\r\ncommunications, speech signals are not orthogonal to their shifts, which makes\r\nacoustic raking a more challenging problem. That is why the correct way to\r\nthink about it is spatial. Instead of explicitly estimating the channel, we\r\ncreate correspondences between early echoes in time and image sources in space.\r\nThese multiple sources of the desired and interfering signals offer additional\r\nspatial diversity that we can exploit in the beamformer design.\r\n\r\nWe present several \"intuitive\" and optimal formulations of ARRs, and show\r\ntheoretically and numerically that the rake formulation of the maximum\r\nsignal-to-interference-and-noise beamformer offers significant performance\r\nboosts in terms of noise suppression and interference cancellation. We\r\naccompany the paper by the complete simulation and processing chain written in\r\nPython.\r\n\r\n\r\nAuthors\r\n-------\r\n\r\nIvan Dokmanić, Robin Scheibler, and Martin Vetterli are with [LCAV](http://lcav.epfl.ch)-[EPFL](http://www.epfl.ch).\r\n\r\n#### Contact\r\n\r\n[Ivan Dokmanić](mailto:ivan[dot]dokmanic[at]epfl[dot]ch) <br>\r\nEPFL-IC-LCAV <br>\r\nBC Building <br>\r\nStation 14 <br>\r\n1015 Lausanne\r\n\r\n\r\nSound Samples\r\n-------------\r\n\r\n* [sample1](https://github.com/LCAV/AcousticRakeReceiver/raw/master/output_samples/input_mic.wav) Simulated microphone input signal.\r\n* [sample2](https://github.com/LCAV/AcousticRakeReceiver/raw/master/output_samples/output_maxsinr.wav) Output of conventional Max-SINR beamformer.\r\n* [sample3](https://github.com/LCAV/AcousticRakeReceiver/raw/master/output_samples/output_rake-maxsinr.wav) Output of proposed  Rake-Max-SINR beamformer.\r\n\r\n\r\nDependencies\r\n------------\r\n\r\n* A working distribution of [Python 2.7](https://www.python.org/downloads/).\r\n\r\n* The code relies heavily on [Numpy](http://www.numpy.org/), [Scipy](http://www.scipy.org/), and [matplotlib](http://matplotlib.org).\r\n\r\n* We use the distribution [anaconda](https://store.continuum.io/cshop/anaconda/) to simplify the setup of the environment.\r\n\r\n\r\nRecreate the figures and sound samples\r\n--------------------------------------\r\n\r\nIn a UNIX terminal, run the following script.\r\n\r\n    ./make_all_figures.sh\r\n\r\nAlternatively, type in the following commands in an ipython shell.\r\n\r\n    run figure_spectrograms.py\r\n    run figure_beam_scenarios.py\r\n    run figure_Measures1.py\r\n    run figure_Measures2.py\r\n    run figure_SumNorm.py\r\n\r\nThe figures and sound samples generated are collected in `figures` and\r\n`output_samples`, respectively.\r\n\r\nLicense\r\n-------\r\n\r\nCopyright (c) 2014, Ivan Dokmanić, Robin Scheibler, Martin Vetterli\r\n\r\nThis code is free to reuse for non-commercial purpose such as academic or\r\neducational. For any other use, please contact the authors.\r\n\r\n<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">Acoustic Rake Receiver</span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://lcav.epfl.ch\" property=\"cc:attributionName\" rel=\"cc:attributionURL\">Ivan Dokmanić, Robin Scheibler, Martin Vetterli</a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.<br />Based on a work at <a xmlns:dct=\"http://purl.org/dc/terms/\" href=\"https://github.com/LCAV/AcousticRakeReceiver\" rel=\"dct:source\">https://github.com/LCAV/AcousticRakeReceiver</a>.\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}